{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db35fde5-535f-48b9-9e12-564bea8bedba",
   "metadata": {},
   "source": [
    "## **README**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c21a315-f5ad-4a6d-af9c-b1641033e444",
   "metadata": {},
   "source": [
    "**Input**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e75b865-5a91-49a5-b13f-ba4d865b63ea",
   "metadata": {},
   "source": [
    "Training/prediction csv data from the rhino-grasshopper simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f61f3b-80ab-44e1-9827-7413818fc149",
   "metadata": {},
   "source": [
    "**Output**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930b929e-34cd-4eed-83f4-1482fa31c29b",
   "metadata": {},
   "source": [
    "Pytorch graph data object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e43a466-4d3c-49e3-9e19-1a77b8da89ce",
   "metadata": {},
   "source": [
    "## **Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14692659-1b83-4390-9a35-be265d139600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch                                 # pytorch\n",
    "from torch_geometric.data import Data        # to work with graph data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0d8c74-f71c-4edb-b5ee-9cfb6fc994fe",
   "metadata": {},
   "source": [
    "## **Pipeline Settings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e41d3212-b6ad-4a09-b8b8-249ccc0f3b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the mode at the start of your code\n",
    "pipeline_mode = \"training\"  # Change to \"prediction\" when needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "075e3a51-8643-4dc7-bc4c-3031abcb960b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Csv Training Data\n",
    "run_num = 'run_4'\n",
    "file_path_training = rf'data\\csv_training\\{run_num}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb460fe-1e14-4314-85ed-70f4421ee7db",
   "metadata": {},
   "source": [
    "**No changes to input below for each run**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6573a7d9-2afa-4c55-b2b2-2f436e7d42cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch Training Path\n",
    "filename_training = rf'data/torch_data_object_training/{run_num}.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4548b764-8ec4-4792-a207-cfd17563fa2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch Prediction Path\n",
    "filename_prediction = rf'data/torch_data_object_prediction/{run_num}.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edbd1f31-c9c4-4307-80bb-5531b8e46e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Csv Files to Import\n",
    "file_names = [ \n",
    "    'building_alum_vertex',\n",
    "    'building_brick_vertex',\n",
    "    'building_conc_vertex',\n",
    "    'building_glass_vertex',\n",
    "    'building_wood_vertex',\n",
    "    'distance_alum',\n",
    "    'distance_brick',\n",
    "    'distance_conc',\n",
    "    'distance_glass',\n",
    "    'distance_wood',\n",
    "    'label',  \n",
    "    'sensor',\n",
    "    'sensor_length',\n",
    "    'vertex_length_alum',\n",
    "    'vertex_length_brick',\n",
    "    'vertex_length_conc',\n",
    "    'vertex_length_glass',\n",
    "    'vertex_length_wood',\n",
    "]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "450e57ba-6527-47c0-a8a1-400420994665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary mapping DataFrame names to material names\n",
    "df_material_map = {\n",
    "    'building_conc_vertex_df': 'exterior_concrete_wall',\n",
    "    'building_glass_vertex_df': 'exterior_glass',\n",
    "    'building_wood_vertex_df': 'exterior_wood_wall',\n",
    "    'building_brick_vertex_df': 'exterior_white_brick',\n",
    "    'building_alum_vertex_df': 'exterior_alum_cladding'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efa4574f-a66a-4ec6-a84e-09b9dd1bcd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to combine into building_df\n",
    "append_list = (\n",
    "    'building_alum_vertex_df_append',\n",
    "    'building_brick_vertex_df_append',\n",
    "    'building_conc_vertex_df_append',\n",
    "    'building_glass_vertex_df_append',\n",
    "    'building_wood_vertex_df_append',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "786dc752-b3b9-41d9-afe0-119e4b663839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of dfs to extract vertex length\n",
    "df_vertex_names = [\n",
    "    'vertex_length_alum_df',\n",
    "    'vertex_length_brick_df',\n",
    "    'vertex_length_conc_df',\n",
    "    'vertex_length_glass_df',\n",
    "    'vertex_length_wood_df'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b6d7be6-3130-481f-bd4d-fc711e0fc9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Material list\n",
    "material_list = ['alum', 'brick','conc', 'glass', 'wood']  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c154157-7b6e-452a-8f10-05e9f65e2945",
   "metadata": {},
   "source": [
    "## **Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "edfbdbf9-8793-472d-b367-6276dc332c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_df(dataframes, line_length=50):\n",
    "    \"\"\"\n",
    "    Prints the head of each DataFrame in the list, separated by a line.\n",
    "\n",
    "    Parameters:\n",
    "    - dataframes (list of tuple): A list where each tuple contains a string (the name of the DataFrame) and a DataFrame.\n",
    "    - line_length (int): The length of the separating line. Default is 50.\n",
    "    \"\"\"\n",
    "    line = '-' * line_length\n",
    "    for name, df in dataframes:\n",
    "        print(name)\n",
    "        print(df.head())\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e87ce78e-15b3-46df-9e0c-76133a1ecfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_nulls_in_dfs(dfs):\n",
    "    \"\"\"\n",
    "    Checks for null values in each DataFrame within a dictionary and prints a message indicating the presence of null values.\n",
    "\n",
    "    Args:\n",
    "    - dfs (dict): A dictionary where each key is the name of a DataFrame and each value is the DataFrame object.\n",
    "    \"\"\"\n",
    "    for df_name, df in dfs.items():\n",
    "        # Check if there are any null values in the DataFrame\n",
    "        if df.isnull().values.any():\n",
    "            print(f'Null values found in \\'{df_name}\\' DataFrame.')\n",
    "        else:\n",
    "            print(f'No null values in \\'{df_name}\\' DataFrame.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5dcfe90a-5551-402d-b789-5994f53583f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_and_insert_id_column(df, id_base_name):\n",
    "    \"\"\"\n",
    "    Resets the index of the DataFrame, creates a new column with formatted IDs based on the new index,\n",
    "    and inserts this new column as the first column of the DataFrame.\n",
    "    \n",
    "    Args:\n",
    "    - df (pd.DataFrame): The DataFrame to operate on.\n",
    "    - id_base_name (str): The base name for the new ID column (e.g., 'sensor_id', 'vertex_id').\n",
    "    \n",
    "    Returns:\n",
    "    - pd.DataFrame: The modified DataFrame with the new ID column as the first column.\n",
    "    \"\"\"\n",
    "    # Resetting the index so the specified ID column is no longer the index column, if it was.\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # Creating a new ID column with formatted values.\n",
    "    df[id_base_name] = [f'{id_base_name}_{i + 1}' for i in df.index]\n",
    "    \n",
    "    # Inserting the new ID column as the first column.\n",
    "    df.insert(0, id_base_name, df.pop(id_base_name))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f08b6887-028b-48f1-b814-bfed5508e32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv_files_as_dict(file_path_training, file_names):\n",
    "    \"\"\"\n",
    "    Loads CSV files into pandas DataFrames and stores them in a dictionary with dynamically constructed keys.\n",
    "    Skips empty CSV files.\n",
    "\n",
    "    Args:\n",
    "    - file_path_training (str): The directory path where the CSV files are stored.\n",
    "    - file_names (list of str): List of file names without the '.csv' extension.\n",
    "\n",
    "    Returns:\n",
    "    - dict: A dictionary where each key is a dynamically constructed name based on the file name and\n",
    "            each value is the corresponding DataFrame loaded from the CSV file.\n",
    "    \"\"\"\n",
    "    # Dictionary to store the DataFrames, with keys as dynamically constructed names\n",
    "    dataframes = {}\n",
    "\n",
    "    # Loop over the list of file names\n",
    "    for file_name in file_names:\n",
    "        file_path = os.path.join(file_path_training, f'{file_name}.csv')\n",
    "        # Check if the file is not empty (size > 0)\n",
    "        if os.path.getsize(file_path) > 0:\n",
    "            # Construct the DataFrame name and load the CSV file into a DataFrame\n",
    "            df_name = f'{file_name}_df'\n",
    "            dataframes[df_name] = pd.read_csv(file_path, header=None)\n",
    "        else:\n",
    "            print(f'Skipped empty file: {file_name}.csv')\n",
    "\n",
    "    return dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60b8ddc9-11ec-4668-8a20-d0ea874a9b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_material_properties(dfs, material_df, df_material_map):\n",
    "    \"\"\"\n",
    "    Appends material properties to each row of specified building DataFrames based on a mapping dictionary,\n",
    "    creating new DataFrames for the appended versions without modifying the originals.\n",
    "    Skips empty DataFrames and those not found in the dfs dictionary.\n",
    "    \n",
    "    Args:\n",
    "    - dfs (dict): Dictionary of DataFrames to be updated, where keys are DataFrame names.\n",
    "    - material_df (pd.DataFrame): DataFrame containing material properties.\n",
    "    - df_material_map (dict): Dictionary mapping DataFrame names to material names.\n",
    "    \n",
    "    Returns:\n",
    "    - dict: The dfs dictionary with new DataFrames added that contain the original data\n",
    "            with material properties appended. The new DataFrames have keys with an `_append` suffix.\n",
    "    \"\"\"\n",
    "    for df_name, material_name in df_material_map.items():\n",
    "        # Construct new DataFrame name with '_append' suffix\n",
    "        new_df_name = f\"{df_name}_append\"\n",
    "        \n",
    "        # Check if the original DataFrame is present in dfs and not empty\n",
    "        if df_name in dfs and not dfs[df_name].empty:\n",
    "            # Find the row in material_df for the specified material\n",
    "            material_row = material_df[material_df['material_name'] == material_name].drop('material_name', axis=1)\n",
    "            # Replicate the material row to match the size of the building DataFrame\n",
    "            repeated_material = pd.concat([material_row] * len(dfs[df_name]), ignore_index=True)\n",
    "            # Create a new DataFrame by appending the material properties\n",
    "            dfs[new_df_name] = pd.concat([dfs[df_name].reset_index(drop=True), repeated_material.reset_index(drop=True)], axis=1)\n",
    "        else:\n",
    "            print(f\"Skipped empty or missing DataFrame: {df_name}\")\n",
    "    \n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da9ff193-a27f-48a2-aeff-8ddf2dc75d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_dataframes_in_order(dfs, append_list):\n",
    "    \"\"\"\n",
    "    Combines a list of DataFrames found in the dictionary 'dfs' into a single DataFrame,\n",
    "    strictly following the order specified in 'append_list'. Skips any DataFrame names\n",
    "    not found in the 'dfs' dictionary.\n",
    "\n",
    "    Args:\n",
    "    - dfs (dict): Dictionary containing DataFrames.\n",
    "    - append_list (tuple): Tuple containing the names of the DataFrames to be combined in order.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: The combined DataFrame.\n",
    "    \"\"\"\n",
    "    combined_df = pd.DataFrame()  # Initialize an empty DataFrame to start with\n",
    "\n",
    "    for df_name in append_list:\n",
    "        if df_name in dfs:  # Check if DataFrame name exists in the dictionary\n",
    "            # If the combined DataFrame is empty, initialize it with the first DataFrame\n",
    "            if combined_df.empty:\n",
    "                combined_df = dfs[df_name].copy()\n",
    "            else:\n",
    "                # Concatenate the current DataFrame to the combined DataFrame\n",
    "                combined_df = pd.concat([combined_df, dfs[df_name]], ignore_index=True)\n",
    "        else:\n",
    "            print(f\"DataFrame name '{df_name}' not found in the dictionary. Skipping...\")\n",
    "\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ef9d629-8bb9-43d1-b8ac-33daa567fa24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_values_to_dict(dfs, df_names):\n",
    "    \"\"\"\n",
    "    Extracts a single value from each specified DataFrame and stores it in a dictionary.\n",
    "\n",
    "    Args:\n",
    "    - dfs (dict): Dictionary containing the DataFrames.\n",
    "    - df_names (list of str): List of the names of the DataFrames to extract values from.\n",
    "\n",
    "    Returns:\n",
    "    - dict: A dictionary with the DataFrame names as keys and their extracted values as values.\n",
    "    \"\"\"\n",
    "    values_dict = {}\n",
    "\n",
    "    for df_name in df_names:\n",
    "        if df_name in dfs and not dfs[df_name].empty:\n",
    "            # Assuming each DataFrame contains only one value, extract it\n",
    "            value = dfs[df_name].iloc[0, 0]  # Extract the first value of the DataFrame\n",
    "            values_dict[df_name] = value\n",
    "        else:\n",
    "            print(f\"DataFrame '{df_name}' does not exist or is empty. Skipping...\")\n",
    "\n",
    "    return values_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5bb53c6-6f74-4886-99b8-7fc2b13cf293",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_sensor_to_vertex(sensor_length, values_dict):\n",
    "    \"\"\"\n",
    "    Creates mappings of sensor IDs to vertex material IDs based on values_dict.\n",
    "    \n",
    "    Args:\n",
    "    - sensor_length (int): The number of sensors.\n",
    "    - values_dict (dict): Dictionary with vertex lengths for each material.\n",
    "    \n",
    "    Returns:\n",
    "    - dict: A dictionary of DataFrames, each representing sensor to vertex mappings for a material.\n",
    "    \"\"\"\n",
    "    mapped_dfs = {}\n",
    "    for material, length in values_dict.items():\n",
    "        material_name = material.split('_df')[0]  # Extract material name from the key\n",
    "        data = [(f'sensor_id_{sensor_id}', f'{material_name}_{i}') for sensor_id in range(1, sensor_length + 1) for i in range(1, length + 1)]\n",
    "        mapped_df = pd.DataFrame(data, columns=['sensor_id', 'vertex_id'])\n",
    "        mapped_dfs[material_name] = mapped_df\n",
    "    \n",
    "    return mapped_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc806568-56ba-4eb7-bdfc-156e6cb220c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_distance_to_mapped_dfs(mapped_dfs, dfs, material_list):\n",
    "    \"\"\"\n",
    "    Correctly appends distance values from distance DataFrames in dfs to each corresponding mapped DataFrame.\n",
    "    Correctly references the material name in mapped_dfs and skips materials if their corresponding distance DataFrame cannot be found in dfs.\n",
    "    \n",
    "    Args:\n",
    "    - mapped_dfs (dict): Dictionary of mapped DataFrames.\n",
    "    - dfs (dict): Dictionary containing distance DataFrames.\n",
    "    - material_list (list): List of materials to search distance data for.\n",
    "    \n",
    "    Returns:\n",
    "    - dict: Updated dictionary of mapped DataFrames with distance values appended.\n",
    "    \"\"\"\n",
    "    for material in material_list:\n",
    "        distance_df_name = f'distance_{material}_df'\n",
    "        mapped_df_name = f'vertex_length_{material}'  # Adjusted to match the naming convention in mapped_dfs\n",
    "\n",
    "        # Check if both the distance DataFrame and the mapped DataFrame exist\n",
    "        if distance_df_name in dfs and mapped_df_name in mapped_dfs:\n",
    "            distance_df = dfs[distance_df_name]\n",
    "            # Assuming the distance values are in the first column of distance_df\n",
    "            mapped_df = mapped_dfs[mapped_df_name]\n",
    "            # Ensure the distance DataFrame has enough rows to match the mapped DataFrame\n",
    "            if len(distance_df) >= len(mapped_df):\n",
    "                mapped_df['distance'] = distance_df.iloc[:len(mapped_df), 0].values\n",
    "            else:\n",
    "                print(f\"Warning: Not enough distance values for {material}, distances not appended.\")\n",
    "            mapped_dfs[mapped_df_name] = mapped_df\n",
    "        else:\n",
    "            # Print a warning if the distance DataFrame is not found\n",
    "            print(f\"Warning: Distance DataFrame for '{material}' not found, skipping.\")\n",
    "\n",
    "    return mapped_dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb0312f-a68a-4e7e-b9bc-593d5d17822d",
   "metadata": {},
   "source": [
    "## **Import Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29d1bd54-1586-4775-af47-f396ce869eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped empty file: building_alum_vertex.csv\n",
      "Skipped empty file: building_brick_vertex.csv\n",
      "Skipped empty file: building_conc_vertex.csv\n",
      "Skipped empty file: building_wood_vertex.csv\n",
      "Skipped empty file: distance_alum.csv\n",
      "Skipped empty file: distance_brick.csv\n",
      "Skipped empty file: distance_conc.csv\n",
      "Skipped empty file: distance_wood.csv\n",
      "Skipped empty file: vertex_length_alum.csv\n",
      "Skipped empty file: vertex_length_brick.csv\n",
      "Skipped empty file: vertex_length_conc.csv\n",
      "Skipped empty file: vertex_length_wood.csv\n"
     ]
    }
   ],
   "source": [
    "# Call function to import csv and convert to dataframe, storing them in a dictionary\n",
    "dfs = load_csv_files_as_dict(file_path_training, file_names)\n",
    "# Access a specific DataFrame, e.g., sensor_df = dfs['sensor_df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a191db67-7196-40fb-8044-90934ebfb709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame Name: building_glass_vertex_df\n",
      "               0           1    2\n",
      "0     549.410357  400.329450    0\n",
      "1     692.361115  425.786135    0\n",
      "2     684.888685  420.990358    0\n",
      "3     684.888685  420.990358  141\n",
      "4     692.361115  425.786135  141\n",
      "...          ...         ...  ...\n",
      "1123  706.706879  393.107683   84\n",
      "1124  705.317466  393.245558    0\n",
      "1125  705.317466  393.245558   84\n",
      "1126  705.653500  395.814835    0\n",
      "1127  705.653500  395.814835   84\n",
      "\n",
      "[1128 rows x 3 columns]\n",
      "\n",
      "DataFrame Name: distance_glass_df\n",
      "                  0\n",
      "0          2.563417\n",
      "1        145.013067\n",
      "2        136.874467\n",
      "3        194.718981\n",
      "4        200.523444\n",
      "...             ...\n",
      "3042211  169.661109\n",
      "3042212  212.239688\n",
      "3042213  168.349888\n",
      "3042214  212.420733\n",
      "3042215  168.578075\n",
      "\n",
      "[3042216 rows x 1 columns]\n",
      "\n",
      "DataFrame Name: label_df\n",
      "               0\n",
      "0     462.467917\n",
      "1     449.364891\n",
      "2     446.899057\n",
      "3     445.936340\n",
      "4     449.246841\n",
      "...          ...\n",
      "2692  585.271027\n",
      "2693  590.101272\n",
      "2694  608.851186\n",
      "2695  622.115258\n",
      "2696  642.951666\n",
      "\n",
      "[2697 rows x 1 columns]\n",
      "\n",
      "DataFrame Name: sensor_df\n",
      "               0           1           2\n",
      "0     549.510620  400.959503    2.482759\n",
      "1     549.510620  400.959503    7.448276\n",
      "2     549.510620  400.959503   12.413793\n",
      "3     549.510620  400.959503   17.379310\n",
      "4     549.510620  400.959503   22.344828\n",
      "...          ...         ...         ...\n",
      "2692  547.221497  400.267548  120.857143\n",
      "2693  547.221497  400.267548  126.000000\n",
      "2694  547.221497  400.267548  131.142853\n",
      "2695  547.221497  400.267548  136.285713\n",
      "2696  547.221497  400.267548  141.428574\n",
      "\n",
      "[2697 rows x 3 columns]\n",
      "\n",
      "DataFrame Name: sensor_length_df\n",
      "      0\n",
      "0  2697\n",
      "\n",
      "DataFrame Name: vertex_length_glass_df\n",
      "      0\n",
      "0  1128\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for df_name, df in dfs.items():\n",
    "    print(f'DataFrame Name: {df_name}')\n",
    "    print(df)\n",
    "    print()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "24749845-48a1-4414-b116-2739d805e0cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame Name: building_glass_vertex_df\n",
      "DataFrame Name: distance_glass_df\n",
      "DataFrame Name: label_df\n",
      "DataFrame Name: sensor_df\n",
      "DataFrame Name: sensor_length_df\n",
      "DataFrame Name: vertex_length_glass_df\n"
     ]
    }
   ],
   "source": [
    "for df_name in dfs:\n",
    "    print(f'DataFrame Name: {df_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cd11d27b-66b0-4d3a-be23-b2760a6b7151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Material Library and append to dfs dictionary of dataframes\n",
    "material_df = pd.read_csv(r'data\\material\\material_library.csv')\n",
    "dfs['material'] = material_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "82c44878-e7ad-40a8-b4d6-682f7b97ff2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>material_name</th>\n",
       "      <th>r_ref</th>\n",
       "      <th>g_ref</th>\n",
       "      <th>b_ref</th>\n",
       "      <th>spec</th>\n",
       "      <th>rough</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>exterior_concrete_wall</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>exterior_wood_wall</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>exterior_alum_cladding</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>exterior_white_brick</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>exterior_glass</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            material_name  r_ref  g_ref  b_ref  spec  rough\n",
       "0  exterior_concrete_wall   0.70   0.69   0.66  0.03    0.3\n",
       "1      exterior_wood_wall   0.15   0.14   0.13  0.48    0.2\n",
       "2  exterior_alum_cladding   0.63   0.63   0.61  0.05    0.1\n",
       "3    exterior_white_brick   0.73   0.65   0.47  0.25    0.3\n",
       "4          exterior_glass   0.70   0.70   0.70  0.00    0.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "material_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81410fad-9fed-4852-805e-e8d57c5e5ccf",
   "metadata": {},
   "source": [
    "## **Check - Null Values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b8c5be48-becf-4913-b568-92554b42c1cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No null values in 'building_glass_vertex_df' DataFrame.\n",
      "No null values in 'distance_glass_df' DataFrame.\n",
      "No null values in 'label_df' DataFrame.\n",
      "No null values in 'sensor_df' DataFrame.\n",
      "No null values in 'sensor_length_df' DataFrame.\n",
      "No null values in 'vertex_length_glass_df' DataFrame.\n",
      "No null values in 'material' DataFrame.\n"
     ]
    }
   ],
   "source": [
    "# Check for Null Values\n",
    "check_nulls_in_dfs(dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8364b358-6023-43be-a3e0-b23057a36d7f",
   "metadata": {},
   "source": [
    "## **Prepare Dataset - building_df**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "694fdc84-7500-40a9-b906-19f442edc74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped empty or missing DataFrame: building_conc_vertex_df\n",
      "Skipped empty or missing DataFrame: building_wood_vertex_df\n",
      "Skipped empty or missing DataFrame: building_brick_vertex_df\n",
      "Skipped empty or missing DataFrame: building_alum_vertex_df\n"
     ]
    }
   ],
   "source": [
    "dfs = append_material_properties(dfs, material_df, df_material_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "45a12b74-07c2-4157-bc67-fcefa3479f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame name 'building_alum_vertex_df_append' not found in the dictionary. Skipping...\n",
      "DataFrame name 'building_brick_vertex_df_append' not found in the dictionary. Skipping...\n",
      "DataFrame name 'building_conc_vertex_df_append' not found in the dictionary. Skipping...\n",
      "DataFrame name 'building_wood_vertex_df_append' not found in the dictionary. Skipping...\n"
     ]
    }
   ],
   "source": [
    "# Create combined building_df\n",
    "building_df = combine_dataframes_in_order(dfs, append_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5f8191-605f-481a-9a04-ae639195c3bd",
   "metadata": {},
   "source": [
    "## **Prepare Dataset - edge_df**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a33dd5f6-6245-447d-8d35-0f2f20e932b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 'vertex_length_alum_df' does not exist or is empty. Skipping...\n",
      "DataFrame 'vertex_length_brick_df' does not exist or is empty. Skipping...\n",
      "DataFrame 'vertex_length_conc_df' does not exist or is empty. Skipping...\n",
      "DataFrame 'vertex_length_wood_df' does not exist or is empty. Skipping...\n"
     ]
    }
   ],
   "source": [
    "values_dict = extract_values_to_dict(dfs, df_vertex_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "10b1ac11-79cd-46f9-bd4c-16b4f4c09ee7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vertex_length_glass_df': 1128}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "245439ae-f968-4c0a-a4ff-fc6adfa4c66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract out the length values and convert to numerical from both dataframes\n",
    "sensor_length = int(dfs['sensor_length_df'].iloc[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f3783bc8-86b6-41d7-9223-a450ec4ecde3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2697"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensor_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "18fbc5d7-618f-4e49-9bcc-84d8288ed595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map sensor length with each material vertex length, return dictionary of dfs\n",
    "mapped_dfs = map_sensor_to_vertex(sensor_length, values_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ecfb9427-c8bf-439d-af50-6458fdf99ac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vertex_length_glass':               sensor_id                 vertex_id\n",
       " 0           sensor_id_1     vertex_length_glass_1\n",
       " 1           sensor_id_1     vertex_length_glass_2\n",
       " 2           sensor_id_1     vertex_length_glass_3\n",
       " 3           sensor_id_1     vertex_length_glass_4\n",
       " 4           sensor_id_1     vertex_length_glass_5\n",
       " ...                 ...                       ...\n",
       " 3042211  sensor_id_2697  vertex_length_glass_1124\n",
       " 3042212  sensor_id_2697  vertex_length_glass_1125\n",
       " 3042213  sensor_id_2697  vertex_length_glass_1126\n",
       " 3042214  sensor_id_2697  vertex_length_glass_1127\n",
       " 3042215  sensor_id_2697  vertex_length_glass_1128\n",
       " \n",
       " [3042216 rows x 2 columns]}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapped_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9f1a46df-7ecd-4492-b96e-2f21c92ff9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Distance DataFrame for 'alum' not found, skipping.\n",
      "Warning: Distance DataFrame for 'brick' not found, skipping.\n",
      "Warning: Distance DataFrame for 'conc' not found, skipping.\n",
      "Warning: Distance DataFrame for 'wood' not found, skipping.\n"
     ]
    }
   ],
   "source": [
    "final_dfs = append_distance_to_mapped_dfs(mapped_dfs, dfs, material_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6fe3e42d-63d5-4a53-98f7-d80dd0f6579d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the keys of final_dfs alphabetically\n",
    "sorted_keys = sorted(final_dfs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a7495c95-097e-43cd-a04e-0a174107b4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the DataFrames in alphabetical order\n",
    "edge_df = pd.concat([final_dfs[key] for key in sorted_keys], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "036da5ed-2d1c-45ef-b2cd-180a05e3e873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor_id</th>\n",
       "      <th>vertex_id</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sensor_id_1</td>\n",
       "      <td>vertex_length_glass_1</td>\n",
       "      <td>2.563417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sensor_id_1</td>\n",
       "      <td>vertex_length_glass_2</td>\n",
       "      <td>145.013067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sensor_id_1</td>\n",
       "      <td>vertex_length_glass_3</td>\n",
       "      <td>136.874467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sensor_id_1</td>\n",
       "      <td>vertex_length_glass_4</td>\n",
       "      <td>194.718981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sensor_id_1</td>\n",
       "      <td>vertex_length_glass_5</td>\n",
       "      <td>200.523444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3042211</th>\n",
       "      <td>sensor_id_2697</td>\n",
       "      <td>vertex_length_glass_1124</td>\n",
       "      <td>169.661109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3042212</th>\n",
       "      <td>sensor_id_2697</td>\n",
       "      <td>vertex_length_glass_1125</td>\n",
       "      <td>212.239688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3042213</th>\n",
       "      <td>sensor_id_2697</td>\n",
       "      <td>vertex_length_glass_1126</td>\n",
       "      <td>168.349888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3042214</th>\n",
       "      <td>sensor_id_2697</td>\n",
       "      <td>vertex_length_glass_1127</td>\n",
       "      <td>212.420733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3042215</th>\n",
       "      <td>sensor_id_2697</td>\n",
       "      <td>vertex_length_glass_1128</td>\n",
       "      <td>168.578075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3042216 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              sensor_id                 vertex_id    distance\n",
       "0           sensor_id_1     vertex_length_glass_1    2.563417\n",
       "1           sensor_id_1     vertex_length_glass_2  145.013067\n",
       "2           sensor_id_1     vertex_length_glass_3  136.874467\n",
       "3           sensor_id_1     vertex_length_glass_4  194.718981\n",
       "4           sensor_id_1     vertex_length_glass_5  200.523444\n",
       "...                 ...                       ...         ...\n",
       "3042211  sensor_id_2697  vertex_length_glass_1124  169.661109\n",
       "3042212  sensor_id_2697  vertex_length_glass_1125  212.239688\n",
       "3042213  sensor_id_2697  vertex_length_glass_1126  168.349888\n",
       "3042214  sensor_id_2697  vertex_length_glass_1127  212.420733\n",
       "3042215  sensor_id_2697  vertex_length_glass_1128  168.578075\n",
       "\n",
       "[3042216 rows x 3 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23889dab-4dab-458a-ac0d-2cb15a30f164",
   "metadata": {},
   "source": [
    "## **Graph Object - Preprocess Node Index and Naming**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "806d58ff-55a7-496e-b80a-ad645ad17926",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_df = format_and_insert_id_column(dfs['sensor_df'], 'sensor_id')\n",
    "building_df = format_and_insert_id_column(building_df, 'vertex_id')\n",
    "label_df = format_and_insert_id_column(dfs['label_df'], 'sensor_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec54a74-4415-41f0-a39e-d0fa84d45fc3",
   "metadata": {},
   "source": [
    "## **Graph Object - Add Column Headers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "98c42708-3725-4f53-9ef7-8b7cbffed5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_df.rename(columns={0: 'sensor_x_coordinate', 1: 'sensor_y_coordinate', 2: 'sensor_z_coordinate'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "93231c37-89f3-4db3-917c-9101f409ba27",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df.columns = ['sensor_id', 'hb_solar_radiation']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2769ae-4067-4b81-99b2-103bc2dd0b65",
   "metadata": {},
   "source": [
    "## **Graph Object - Midpoint Check**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "feb11520-4bc4-48e4-864b-8bbe2267a841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sensor_df',\n",
       "             sensor_id  sensor_x_coordinate  sensor_y_coordinate  \\\n",
       "  0        sensor_id_1           549.510620           400.959503   \n",
       "  1        sensor_id_2           549.510620           400.959503   \n",
       "  2        sensor_id_3           549.510620           400.959503   \n",
       "  3        sensor_id_4           549.510620           400.959503   \n",
       "  4        sensor_id_5           549.510620           400.959503   \n",
       "  ...              ...                  ...                  ...   \n",
       "  2692  sensor_id_2693           547.221497           400.267548   \n",
       "  2693  sensor_id_2694           547.221497           400.267548   \n",
       "  2694  sensor_id_2695           547.221497           400.267548   \n",
       "  2695  sensor_id_2696           547.221497           400.267548   \n",
       "  2696  sensor_id_2697           547.221497           400.267548   \n",
       "  \n",
       "        sensor_z_coordinate  \n",
       "  0                2.482759  \n",
       "  1                7.448276  \n",
       "  2               12.413793  \n",
       "  3               17.379310  \n",
       "  4               22.344828  \n",
       "  ...                   ...  \n",
       "  2692           120.857143  \n",
       "  2693           126.000000  \n",
       "  2694           131.142853  \n",
       "  2695           136.285713  \n",
       "  2696           141.428574  \n",
       "  \n",
       "  [2697 rows x 4 columns]),\n",
       " ('building_df',\n",
       "             vertex_id           0           1    2  r_ref  g_ref  b_ref  spec  \\\n",
       "  0        vertex_id_1  549.410357  400.329450    0    0.7    0.7    0.7   0.0   \n",
       "  1        vertex_id_2  692.361115  425.786135    0    0.7    0.7    0.7   0.0   \n",
       "  2        vertex_id_3  684.888685  420.990358    0    0.7    0.7    0.7   0.0   \n",
       "  3        vertex_id_4  684.888685  420.990358  141    0.7    0.7    0.7   0.0   \n",
       "  4        vertex_id_5  692.361115  425.786135  141    0.7    0.7    0.7   0.0   \n",
       "  ...              ...         ...         ...  ...    ...    ...    ...   ...   \n",
       "  1123  vertex_id_1124  706.706879  393.107683   84    0.7    0.7    0.7   0.0   \n",
       "  1124  vertex_id_1125  705.317466  393.245558    0    0.7    0.7    0.7   0.0   \n",
       "  1125  vertex_id_1126  705.317466  393.245558   84    0.7    0.7    0.7   0.0   \n",
       "  1126  vertex_id_1127  705.653500  395.814835    0    0.7    0.7    0.7   0.0   \n",
       "  1127  vertex_id_1128  705.653500  395.814835   84    0.7    0.7    0.7   0.0   \n",
       "  \n",
       "        rough  \n",
       "  0       0.0  \n",
       "  1       0.0  \n",
       "  2       0.0  \n",
       "  3       0.0  \n",
       "  4       0.0  \n",
       "  ...     ...  \n",
       "  1123    0.0  \n",
       "  1124    0.0  \n",
       "  1125    0.0  \n",
       "  1126    0.0  \n",
       "  1127    0.0  \n",
       "  \n",
       "  [1128 rows x 9 columns]),\n",
       " ('label_df',\n",
       "             sensor_id  hb_solar_radiation\n",
       "  0        sensor_id_1          462.467917\n",
       "  1        sensor_id_2          449.364891\n",
       "  2        sensor_id_3          446.899057\n",
       "  3        sensor_id_4          445.936340\n",
       "  4        sensor_id_5          449.246841\n",
       "  ...              ...                 ...\n",
       "  2692  sensor_id_2693          585.271027\n",
       "  2693  sensor_id_2694          590.101272\n",
       "  2694  sensor_id_2695          608.851186\n",
       "  2695  sensor_id_2696          622.115258\n",
       "  2696  sensor_id_2697          642.951666\n",
       "  \n",
       "  [2697 rows x 2 columns]),\n",
       " ('edge_df',\n",
       "                sensor_id                 vertex_id    distance\n",
       "  0           sensor_id_1     vertex_length_glass_1    2.563417\n",
       "  1           sensor_id_1     vertex_length_glass_2  145.013067\n",
       "  2           sensor_id_1     vertex_length_glass_3  136.874467\n",
       "  3           sensor_id_1     vertex_length_glass_4  194.718981\n",
       "  4           sensor_id_1     vertex_length_glass_5  200.523444\n",
       "  ...                 ...                       ...         ...\n",
       "  3042211  sensor_id_2697  vertex_length_glass_1124  169.661109\n",
       "  3042212  sensor_id_2697  vertex_length_glass_1125  212.239688\n",
       "  3042213  sensor_id_2697  vertex_length_glass_1126  168.349888\n",
       "  3042214  sensor_id_2697  vertex_length_glass_1127  212.420733\n",
       "  3042215  sensor_id_2697  vertex_length_glass_1128  168.578075\n",
       "  \n",
       "  [3042216 rows x 3 columns])]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes = [\n",
    "    ('sensor_df', sensor_df),\n",
    "    ('building_df', building_df),\n",
    "    ('label_df', label_df),\n",
    "    ('edge_df', edge_df)\n",
    "]\n",
    "\n",
    "dataframes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ef21fd46-79b5-441f-ab7b-12182fb23db0",
   "metadata": {},
   "source": [
    "## **Graph Object - Prepare Node Features**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155f9316-c11f-4392-8b6e-2fabe38ffbbc",
   "metadata": {},
   "source": [
    "Combine sensor and building information to create a unified node feature matrix. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35e1202-2503-446b-ab65-1e3c889fc3b4",
   "metadata": {},
   "source": [
    "Combine sensor_df and building_df into a single dataframe, ensuring each has a unique identifier across sensors and vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "70667176-f1ae-4007-89f1-f80078fa575f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column to distinguish between sensors and vertices\n",
    "sensor_df['type'] = 'sensor'\n",
    "building_df['type'] = 'vertex'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "258302b5-a7b9-4900-956a-93c9d2a1cf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine dataframes\n",
    "all_nodes_df = pd.concat([sensor_df.assign(index=range(0, len(sensor_df))),\n",
    "                          building_df.assign(index=range(len(sensor_df), len(sensor_df)+len(building_df)))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8204854a-4712-415f-a370-80b80c7136ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor_id</th>\n",
       "      <th>sensor_x_coordinate</th>\n",
       "      <th>sensor_y_coordinate</th>\n",
       "      <th>sensor_z_coordinate</th>\n",
       "      <th>type</th>\n",
       "      <th>index</th>\n",
       "      <th>vertex_id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>r_ref</th>\n",
       "      <th>g_ref</th>\n",
       "      <th>b_ref</th>\n",
       "      <th>spec</th>\n",
       "      <th>rough</th>\n",
       "      <th>type_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sensor_id_1</td>\n",
       "      <td>549.51062</td>\n",
       "      <td>400.959503</td>\n",
       "      <td>2.482759</td>\n",
       "      <td>sensor</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sensor_id_2</td>\n",
       "      <td>549.51062</td>\n",
       "      <td>400.959503</td>\n",
       "      <td>7.448276</td>\n",
       "      <td>sensor</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sensor_id_3</td>\n",
       "      <td>549.51062</td>\n",
       "      <td>400.959503</td>\n",
       "      <td>12.413793</td>\n",
       "      <td>sensor</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sensor_id_4</td>\n",
       "      <td>549.51062</td>\n",
       "      <td>400.959503</td>\n",
       "      <td>17.379310</td>\n",
       "      <td>sensor</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sensor_id_5</td>\n",
       "      <td>549.51062</td>\n",
       "      <td>400.959503</td>\n",
       "      <td>22.344828</td>\n",
       "      <td>sensor</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>vertex</td>\n",
       "      <td>3820</td>\n",
       "      <td>vertex_id_1124</td>\n",
       "      <td>706.706879</td>\n",
       "      <td>393.107683</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1124</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>vertex</td>\n",
       "      <td>3821</td>\n",
       "      <td>vertex_id_1125</td>\n",
       "      <td>705.317466</td>\n",
       "      <td>393.245558</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>vertex</td>\n",
       "      <td>3822</td>\n",
       "      <td>vertex_id_1126</td>\n",
       "      <td>705.317466</td>\n",
       "      <td>393.245558</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>vertex</td>\n",
       "      <td>3823</td>\n",
       "      <td>vertex_id_1127</td>\n",
       "      <td>705.653500</td>\n",
       "      <td>395.814835</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1127</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>vertex</td>\n",
       "      <td>3824</td>\n",
       "      <td>vertex_id_1128</td>\n",
       "      <td>705.653500</td>\n",
       "      <td>395.814835</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3825 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        sensor_id  sensor_x_coordinate  sensor_y_coordinate  \\\n",
       "0     sensor_id_1            549.51062           400.959503   \n",
       "1     sensor_id_2            549.51062           400.959503   \n",
       "2     sensor_id_3            549.51062           400.959503   \n",
       "3     sensor_id_4            549.51062           400.959503   \n",
       "4     sensor_id_5            549.51062           400.959503   \n",
       "...           ...                  ...                  ...   \n",
       "1123          NaN                  NaN                  NaN   \n",
       "1124          NaN                  NaN                  NaN   \n",
       "1125          NaN                  NaN                  NaN   \n",
       "1126          NaN                  NaN                  NaN   \n",
       "1127          NaN                  NaN                  NaN   \n",
       "\n",
       "      sensor_z_coordinate    type  index       vertex_id           0  \\\n",
       "0                2.482759  sensor      0             NaN         NaN   \n",
       "1                7.448276  sensor      1             NaN         NaN   \n",
       "2               12.413793  sensor      2             NaN         NaN   \n",
       "3               17.379310  sensor      3             NaN         NaN   \n",
       "4               22.344828  sensor      4             NaN         NaN   \n",
       "...                   ...     ...    ...             ...         ...   \n",
       "1123                  NaN  vertex   3820  vertex_id_1124  706.706879   \n",
       "1124                  NaN  vertex   3821  vertex_id_1125  705.317466   \n",
       "1125                  NaN  vertex   3822  vertex_id_1126  705.317466   \n",
       "1126                  NaN  vertex   3823  vertex_id_1127  705.653500   \n",
       "1127                  NaN  vertex   3824  vertex_id_1128  705.653500   \n",
       "\n",
       "               1     2  r_ref  g_ref  b_ref  spec  rough  type_flag  \n",
       "0            NaN   NaN    NaN    NaN    NaN   NaN    NaN          1  \n",
       "1            NaN   NaN    NaN    NaN    NaN   NaN    NaN          1  \n",
       "2            NaN   NaN    NaN    NaN    NaN   NaN    NaN          1  \n",
       "3            NaN   NaN    NaN    NaN    NaN   NaN    NaN          1  \n",
       "4            NaN   NaN    NaN    NaN    NaN   NaN    NaN          1  \n",
       "...          ...   ...    ...    ...    ...   ...    ...        ...  \n",
       "1123  393.107683  84.0    0.7    0.7    0.7   0.0    0.0          0  \n",
       "1124  393.245558   0.0    0.7    0.7    0.7   0.0    0.0          0  \n",
       "1125  393.245558  84.0    0.7    0.7    0.7   0.0    0.0          0  \n",
       "1126  395.814835   0.0    0.7    0.7    0.7   0.0    0.0          0  \n",
       "1127  395.814835  84.0    0.7    0.7    0.7   0.0    0.0          0  \n",
       "\n",
       "[3825 rows x 16 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare node features - example: using coordinates and a type flag (sensor=1, vertex=0)\n",
    "all_nodes_df['type_flag'] = all_nodes_df['type'].apply(lambda x: 1 if x == 'sensor' else 0)\n",
    "node_features = all_nodes_df[['sensor_x_coordinate', 'sensor_y_coordinate', 'sensor_z_coordinate', 'type_flag']].fillna(0).values\n",
    "x = torch.tensor(node_features, dtype=torch.float)\n",
    "\n",
    "# Print Check\n",
    "all_nodes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "948db22e-2020-4f92-a7a0-5a2cea6670ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node Features Tensor:\n",
      "tensor([[549.5106, 400.9595,   2.4828,   1.0000],\n",
      "        [549.5106, 400.9595,   7.4483,   1.0000],\n",
      "        [549.5106, 400.9595,  12.4138,   1.0000],\n",
      "        ...,\n",
      "        [  0.0000,   0.0000,   0.0000,   0.0000],\n",
      "        [  0.0000,   0.0000,   0.0000,   0.0000],\n",
      "        [  0.0000,   0.0000,   0.0000,   0.0000]])\n"
     ]
    }
   ],
   "source": [
    "# Print the tensor to check its contents\n",
    "print(\"Node Features Tensor:\")\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2953cfbd-a75a-4544-950c-d585b5809dd3",
   "metadata": {},
   "source": [
    "## **Graph Object - Create Edge Index**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b040ec-1c44-4ec0-88b4-2defde195512",
   "metadata": {},
   "source": [
    "1. Map each sensor_id and vertex_id to a unique index.\r",
    "2. \n",
    "Use these mappings to create the edge_index tensor from edge_df."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d56230c-3508-456b-9a8e-7794340bb63c",
   "metadata": {},
   "source": [
    "Step 1: Prepare Mappings\n",
    "First, we'll create dictionaries to map sensor_id and vertex_id to unique indices. We'll concatenate the indices of sensors and vertices to ensure uniqueness across the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "802d6696-3ca8-43e9-8bd9-bd4a45ae9eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_ids = sensor_df['sensor_id'].unique()\n",
    "vertex_ids = building_df['vertex_id'].unique()\n",
    "\n",
    "# Create a continuous index for sensors and vertices\n",
    "sensor_index = {sensor_id: i for i, sensor_id in enumerate(sensor_ids)}\n",
    "vertex_index = {vertex_id: i + len(sensor_index) for i, vertex_id in enumerate(vertex_ids)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9013e73-bb7b-48c1-92c0-e849c2337d3c",
   "metadata": {},
   "source": [
    "Step 2: Create Edge Index\n",
    "Next, we'll use these mappings to create the edge_index tensor. Note that the vertex_id in edge_df appears to have a slight discrepancy (missing the \"id_\" part based on the example provided), so we'll adjust for that in our mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dcf3d903-c5d7-4e31-a89d-296ab8c39909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust the vertex_id in edge_df to match the format in buildings_df\n",
    "edge_df['adjusted_vertex_id'] = edge_df['vertex_id'].apply(lambda x: 'vertex_id_' + x.split('_')[-1])\n",
    "\n",
    "# Map sensor_id and vertex_id to their respective indices\n",
    "edge_index_list = edge_df.apply(lambda row: [sensor_index.get(row['sensor_id'], -1),\n",
    "                                             vertex_index.get(row['adjusted_vertex_id'], -1)], axis=1)\n",
    "\n",
    "# Filter out any edges that couldn't be mapped (-1 indicates a mapping failure)\n",
    "filtered_edge_index_list = [pair for pair in edge_index_list if -1 not in pair]\n",
    "\n",
    "# Convert to torch tensor\n",
    "edge_index = torch.tensor(filtered_edge_index_list, dtype=torch.long).t().contiguous()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1c3c4bbe-4b74-42f4-b234-2293f84ba2cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,    0,    0,  ..., 2696, 2696, 2696],\n",
       "        [2697, 2698, 2699,  ..., 3822, 3823, 3824]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6117a6dc-0016-458d-b91c-ba2643516ee2",
   "metadata": {},
   "source": [
    "## **Graph Object - Edge Attributes**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a05a096-355f-4148-aeb3-5f6a9c6fdd80",
   "metadata": {},
   "source": [
    "This section extracts edge attributes from the edge_df and converts them into a torch tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3a7ea40e-be0b-4c61-8a2e-d4aabe65bf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_attr = torch.tensor(edge_df[['distance']].values, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cb465579-dd5e-487e-a4ed-fc23f58f80b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  2.5634],\n",
       "        [145.0131],\n",
       "        [136.8745],\n",
       "        ...,\n",
       "        [168.3499],\n",
       "        [212.4207],\n",
       "        [168.5781]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_attr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc442d44-235d-4424-84e5-a051fc9bfc42",
   "metadata": {},
   "source": [
    "## **Graph Object - Target Labels**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccea2750-e585-47eb-aa32-66d55507be4b",
   "metadata": {},
   "source": [
    "This sections prepares the labels for sensors by:\n",
    "1. Aligning with their respective indices\n",
    "2. Converting to a torch tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cb2d302c-d47e-4213-8696-86b5b2cf333a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure data type compatibility\n",
    "label_df['hb_solar_radiation'] = label_df['hb_solar_radiation'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9f496e81-8c1f-436e-b5c4-cdbaf06dd4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update labels for sensors with their radiation values\n",
    "label_df['index'] = label_df['sensor_id'].map(sensor_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e1ef8b79-c059-40d0-b30e-96b5513446c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create torch tensor with compatible data type\n",
    "labels = torch.zeros(len(label_df), dtype=torch.float)\n",
    "labels[label_df['index']] = torch.tensor(label_df['hb_solar_radiation'].values, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e75d86-6550-4080-9db8-505d5059b2c5",
   "metadata": {},
   "source": [
    "## **Graph Object - Creating & Saving the Pytorch Data Object**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6ea13c0f-b549-47eb-8580-f1acaef52ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Object for Training:\n",
      "Data(x=[3825, 4], edge_index=[2, 3042216], edge_attr=[3042216, 1], y=[2697])\n",
      "Training data saved as data/torch_data_object_training/run_4.pt\n"
     ]
    }
   ],
   "source": [
    "if pipeline_mode == \"training\":\n",
    "    # Creating the Data object for training\n",
    "    data_training = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=labels)\n",
    "    print(\"Data Object for Training:\")\n",
    "    print(data_training)\n",
    "\n",
    "    # Saving the training data\n",
    "    torch.save(data_training, filename_training)\n",
    "    print(f\"Training data saved as {filename_training}\")\n",
    "\n",
    "elif pipeline_mode == \"prediction\":\n",
    "    # Creating the Data object for prediction (without labels)\n",
    "    data_predict = Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n",
    "    print(\"Data Object for Prediction:\")\n",
    "    print(data_predict)\n",
    "\n",
    "    # Saving the prediction data\n",
    "    torch.save(data_predict, filename_prediction)\n",
    "    print(f\"Prediction data saved as {filename_prediction}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
